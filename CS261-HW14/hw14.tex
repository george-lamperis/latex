\RequirePackage[l2tabu, orthodox]{nag}

\documentclass[letterpaper, 12pt, oneside]{memoir}
\usepackage{amsmath,amsthm,amssymb,mathtools}
\usepackage{float} % H option to place tables exactly

% Memoir configuration
\pagestyle{plain}
\setlength{\parindent}{0cm}
\setlength{\parskip}{1ex}

% Omit chapter numbering
\counterwithout{section}{chapter}

% ------------------------------------------------------------------------------
% Begin Document
% ------------------------------------------------------------------------------
\title{CS 261 - Homework w14}
\author{George Lamperis}
\date{}

\begin{document}
\maketitle

\section{Data}

\subsection{blocking.cc}
For every test with blocking.cc, we have 4,200,000 accesses. This data 
was taken using a direct mapped cache.

Blocking Factor: 20
Matrix size: 100
% ------------------------------------------------------------------------------
% blocking.cc
% ------------------------------------------------------------------------------
\begin{table}[H]
\centering
\begin{tabular}{c|c|c|r}
    Cache Size (KB)  & Block Size & Miss Rate & Total time \\ \hline 
    4  & 1 & 4.5    & 62865020 \\
    4  & 2 & 3.0    & 56889120 \\
    4  & 4 & 2.3    & 55645940 \\
    4  & 8 & 2.8    & 63088080 \\ \hline
    8  & 1 & 3.4    & 57504170 \\
    8  & 2 & 2.0    & 51951240 \\
    8  & 4 & 1.4    & 49987280 \\
    8  & 8 & 1.4    & 52446660 \\ \hline
    16 & 1 & 2.9    & 55605900 \\
    16 & 2 & 1.6    & 50142720 \\
    16 & 4 & 1.0    & 47808600 \\
    16 & 8 & 0.9    & 48560640 \\ \hline
    32 & 1 & 2.0    & 51315570 \\
    32 & 2 & 1.1    & 47424360 \\
    32 & 4 & 0.6    & 45652320 \\
    32 & 8 & 0.5    & 45765420 \\
\end{tabular}
\caption{blocking.cc}
\end{table}

\subsection{obvious.cc}
For every test with obvious.cc, we have 4,040,000 accesses.

Matrix size: 100
% ------------------------------------------------------------------------------
% obvious.cc
% ------------------------------------------------------------------------------
\begin{table}[H]
\centering
\begin{tabular}{c|c|c|r}
    Cache Size (KB)  & Block Size & Miss Rate & Total time \\ \hline 
    4  & 1 & 27.7   & 163548630 \\
    4  & 2 & 16.5   & 120387320 \\
    4  & 4 & 10.9   & 102084280 \\
    4  & 8 & 20.6   & 190459340 \\ \hline
    8  & 1 & 26.5   & 158077340 \\
    8  & 2 & 14.5   & 110739680 \\
    8  & 4 & 8.5    & 88656040 \\
    8  & 8 & 18.8   & 177242300 \\ \hline
    16 & 1 & 25.8   & 155259360 \\
    16 & 2 & 13.5   & 106037600 \\
    16 & 4 & 7.4    & 82203580 \\
    16 & 8 & 18.0   & 171396080 \\ \hline
    32 & 1 & 10.5   & 87068490 \\
    32 & 2 & 5.6    & 67332680 \\
    32 & 4 & 3.1    & 57918480 \\
    32 & 8 & 1.9    & 54344780 \\
\end{tabular}
\caption{obvious.cc}
\end{table}

\subsection{Hardware}

Matrix size: 1000
Blocking factor: 50
\begin{table}[H]
\centering
\begin{tabular}{c|c}
    Program & Execution Time (seconds) \\ \hline
    blocking.cc        & 8.26 \\
    obvious.cc         & 15.04 \\
    blocking.cc (-O2)  & 1.20 \\
    obvious.cc  (-O2)  & 16.39
\end{tabular}
\caption{hardware data}
\end{table}

\subsection{Associativity}
We'll use a blcok size of 1

\begin{table}[H]
\centering
\begin{tabular}{c|c|r}
    Associativity & Miss Rate (blocking.cc) & Total Time \\ \hline
    1           & 4.5   & 62865020 \\
    2           & 4.2   & 70003210 \\
    4           & 2.6   & 79303410 \\
    8           & 2.6   & 112900110 \\
    16          & 2.6   & 180100110 \\
    1024 (fully) & 2.6   & 8647300110 \\ \hline
    1           & 2.0   & 51315570 \\
    2           & 2.0   & 59717880 \\
    4           & 1.8   & 75466170 \\
    8           & 1.7   & 108500110 \\
    16          & 1.7   & 175700110 \\
    8192 (fully) & 1.7  & 68854100110 \\
\end{tabular}
\caption{blocking.cc with 4 kb cache (top) and 32 kb cache (bottom)}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{c|c|r}
    Associativity & Miss Rate (blocking.cc) & Total Time \\ \hline
    1           & 27.7  & 163548630 \\
    2           & 25.3  & 160724110 \\
    4           & 25.2  & 176840660 \\
    8           & 25.2  & 209160110 \\
    16          & 25.2  & 273800110 \\
    1024 (fully) & 25.2  & 8418440110 \\ \hline
    1           & 10.5  & 87068490 \\
    2           & 14.9  & 114713090 \\
    4           & 23.2  & 167921640 \\
    8           & 25.2  & 209160110 \\
    16          & 25.2  & 273800110 \\
    8192 (fully) & 25.2 & 66335880110 \\
\end{tabular}
\caption{obvious.cc with 4 kb cache (top) and 32 kb cache (bottom)}
\end{table}

\subsection{Blocking factor}
block size 1

\begin{table}[H]
\centering
\begin{tabular}{c|c|c}
    Blocking factor & Miss Rate (4 kb) & Miss Rate (32 kb) \\ \hline
    1   & 14.2  & 5.3 \\
    10  & 5.5   & 2.3 \\
    20  & 4.5   & 2.0 \\
    30  & 10.4  & 2.0 \\
    40  & 21.0  & 2.0 \\
    50  & 26.7  & 1.8 \\
    60  & 26.9  & 1.9 \\
    70  & \\
    80  & \\
    90  & \\
    100 & \\
    
\end{tabular}
\caption{different blocking factors with matrix size 100}
\end{table}

% ------------------------------------------------------------------------------
% Questions
% ------------------------------------------------------------------------------
\section{Discussion Questions}
\subsection{1}
A comparison of blocking.cc and obvious.cc in terms of their algorithmic 
complexity and cache-friendliness. Why did increasing the block size sometimes 
increase the miss rate?

The obvious algorithm appears less complex, with only three nested loops, as
opposed to five nested using the blocking algorithm. One might think that
fewer nested loops would imply a faster execution time. 


Increasing the block size decreases the miss rate because when you request
one byte of memory, the entire block in which that byte is stored gets loaded
into the cache. Since we're dealing with large arrays, those extra values which
get loaded into the cache end up being used also.


\subsection{2}
What would be the optimal blockingFactor to use for matrix multiplication?


\subsection{3}
A discussion of the significance of the results, given that all of the simulated
caches were considerably smaller than current hardware caches.


\subsection{4}
Does increased associativity always reduce the miss rate?

No, increased associativity seems to keep miss rate constant. However, execution
time increases because high associativity becomes slower to implement at 
the hardware level.

Clearly, fully associative is only feasible with really small memory. Even then, 
associativity has diminishing returns. As you increase associativity, the miss
rate remains constant, but the total running time increases.

\subsection{5}
How are caches implemented in hardware? Why does the simulator insist that the
block size, and the number of sets, must be a whole power of two? Is it always
necessary to store the entire block address in the cache for identification purposes?


\subsection{6}
Why does a main memory access involve a significant, fixed overhead? How can 
main memory systems be designed to support caches?


\subsection{7}
What are the attractions of a multilevel caching strategy?





\end{document}
